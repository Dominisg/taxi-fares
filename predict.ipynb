{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import backend\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# def init_session():\n",
    "#     tf_config = tf.ConfigProto()\n",
    "#     tf_config.allow_soft_placement = True\n",
    "#     tf_config.gpu_options.allow_growth = True\n",
    "#     tf_config.gpu_options.visible_device_list = str(0)\n",
    "#     sess=tf.Session(config=tf_config)\n",
    "\n",
    "#     keras.backend.set_session(sess)\n",
    "\n",
    "# init_session()\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9031622</th>\n",
       "      <td>8.500000</td>\n",
       "      <td>2015-01-17 18:59:00</td>\n",
       "      <td>-73.987869</td>\n",
       "      <td>40.765583</td>\n",
       "      <td>-73.974632</td>\n",
       "      <td>40.783310</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22554761</th>\n",
       "      <td>22.500000</td>\n",
       "      <td>2012-04-14 17:31:00</td>\n",
       "      <td>-73.989304</td>\n",
       "      <td>40.726315</td>\n",
       "      <td>-73.921013</td>\n",
       "      <td>40.657829</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12970081</th>\n",
       "      <td>4.900000</td>\n",
       "      <td>2011-03-01 07:19:00</td>\n",
       "      <td>-73.995384</td>\n",
       "      <td>40.733250</td>\n",
       "      <td>-73.990784</td>\n",
       "      <td>40.745449</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28899305</th>\n",
       "      <td>34.330002</td>\n",
       "      <td>2013-10-30 20:05:00</td>\n",
       "      <td>-73.872513</td>\n",
       "      <td>40.774143</td>\n",
       "      <td>-73.978508</td>\n",
       "      <td>40.766727</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2065870</th>\n",
       "      <td>16.330000</td>\n",
       "      <td>2014-04-12 14:42:00</td>\n",
       "      <td>-73.956367</td>\n",
       "      <td>40.747433</td>\n",
       "      <td>-73.977188</td>\n",
       "      <td>40.745403</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42797114</th>\n",
       "      <td>11.300000</td>\n",
       "      <td>2009-08-07 08:48:00</td>\n",
       "      <td>-73.989250</td>\n",
       "      <td>40.740707</td>\n",
       "      <td>-73.959023</td>\n",
       "      <td>40.764175</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32346852</th>\n",
       "      <td>8.900000</td>\n",
       "      <td>2011-09-29 01:23:00</td>\n",
       "      <td>-73.979713</td>\n",
       "      <td>40.776134</td>\n",
       "      <td>-73.953529</td>\n",
       "      <td>40.768421</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43239639</th>\n",
       "      <td>11.500000</td>\n",
       "      <td>2012-11-15 15:11:00</td>\n",
       "      <td>-73.982742</td>\n",
       "      <td>40.762207</td>\n",
       "      <td>-73.978142</td>\n",
       "      <td>40.786243</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52252514</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>2015-05-08 19:56:00</td>\n",
       "      <td>-73.968582</td>\n",
       "      <td>40.754387</td>\n",
       "      <td>-74.003204</td>\n",
       "      <td>40.733601</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3708070</th>\n",
       "      <td>8.100000</td>\n",
       "      <td>2009-04-02 20:48:00</td>\n",
       "      <td>-73.946167</td>\n",
       "      <td>40.709930</td>\n",
       "      <td>-73.953033</td>\n",
       "      <td>40.708992</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          fare_amount     pickup_datetime  pickup_longitude  pickup_latitude  \\\n",
       "key                                                                            \n",
       "9031622      8.500000 2015-01-17 18:59:00        -73.987869        40.765583   \n",
       "22554761    22.500000 2012-04-14 17:31:00        -73.989304        40.726315   \n",
       "12970081     4.900000 2011-03-01 07:19:00        -73.995384        40.733250   \n",
       "28899305    34.330002 2013-10-30 20:05:00        -73.872513        40.774143   \n",
       "2065870     16.330000 2014-04-12 14:42:00        -73.956367        40.747433   \n",
       "42797114    11.300000 2009-08-07 08:48:00        -73.989250        40.740707   \n",
       "32346852     8.900000 2011-09-29 01:23:00        -73.979713        40.776134   \n",
       "43239639    11.500000 2012-11-15 15:11:00        -73.982742        40.762207   \n",
       "52252514    13.000000 2015-05-08 19:56:00        -73.968582        40.754387   \n",
       "3708070      8.100000 2009-04-02 20:48:00        -73.946167        40.709930   \n",
       "\n",
       "          dropoff_longitude  dropoff_latitude  passenger_count  \n",
       "key                                                             \n",
       "9031622          -73.974632         40.783310                1  \n",
       "22554761         -73.921013         40.657829                1  \n",
       "12970081         -73.990784         40.745449                1  \n",
       "28899305         -73.978508         40.766727                1  \n",
       "2065870          -73.977188         40.745403                1  \n",
       "42797114         -73.959023         40.764175                1  \n",
       "32346852         -73.953529         40.768421                2  \n",
       "43239639         -73.978142         40.786243                1  \n",
       "52252514         -74.003204         40.733601                2  \n",
       "3708070          -73.953033         40.708992                1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw=pd.read_pickle(\"train.pkl\")\n",
    "train_raw.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manhattan(pickup_lat, pickup_long, dropoff_lat, dropoff_long):\n",
    "    return np.abs(dropoff_lat - pickup_lat) + np.abs(dropoff_long - pickup_long)\n",
    "\n",
    "def add_distances_features(df):\n",
    "    # Add distances from airpot and downtown\n",
    "    ny = (-74.0063889, 40.7141667)\n",
    "    jfk = (-73.7822222222, 40.6441666667)\n",
    "    ewr = (-74.175, 40.69)\n",
    "    lgr = (-73.87, 40.77)\n",
    "    \n",
    "    lat1 = df['pickup_latitude']\n",
    "    lat2 = df['dropoff_latitude']\n",
    "    lon1 = df['pickup_longitude']\n",
    "    lon2 = df['dropoff_longitude']\n",
    "    \n",
    "    df['euclidean'] = (df['diff_longitude'] ** 2 + df['diff_latitude'] ** 2) ** 0.5\n",
    "    df['manhattan'] = manhattan(lat1, lon1, lat2, lon2)\n",
    "    \n",
    "    df['downtown_pickup_distance'] = manhattan(ny[1], ny[0], lat1, lon1)\n",
    "    df['downtown_dropoff_distance'] = manhattan(ny[1], ny[0], lat2, lon2)\n",
    "    df['jfk_pickup_distance'] = manhattan(jfk[1], jfk[0], lat1, lon1)\n",
    "    df['jfk_dropoff_distance'] = manhattan(jfk[1], jfk[0], lat2, lon2)\n",
    "    df['ewr_pickup_distance'] = manhattan(ewr[1], ewr[0], lat1, lon1)\n",
    "    df['ewr_dropoff_distance'] = manhattan(ewr[1], ewr[0], lat2, lon2)\n",
    "    df['lgr_pickup_distance'] = manhattan(lgr[1], lgr[0], lat1, lon1)\n",
    "    df['lgr_dropoff_distance'] = manhattan(lgr[1], lgr[0], lat2, lon2)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def prepare_features(df):\n",
    "    dtcol=pd.DatetimeIndex(df['pickup_datetime'])    \n",
    "    df['year']=dtcol.year\n",
    "    df['hour']=dtcol.hour\n",
    "    df['day_of_week']=dtcol.dayofweek\n",
    "    df['day_of_year']=dtcol.dayofyear\n",
    "\n",
    "    df['diff_longitude'] = (df.dropoff_longitude -df.pickup_longitude).abs()\n",
    "    df['diff_latitude'] = (df.dropoff_latitude - df.pickup_latitude).abs()\n",
    "    \n",
    "    #reverse incorrectly assigned longitude/latitude values\n",
    "    df = df.assign(rev=df.dropoff_latitude<df.dropoff_longitude)\n",
    "    idx = (df['rev'] == 1)\n",
    "    df.loc[idx,['dropoff_longitude','dropoff_latitude']] = df.loc[idx,['dropoff_latitude','dropoff_longitude']].values\n",
    "    df.loc[idx,['pickup_longitude','pickup_latitude']] = df.loc[idx,['pickup_latitude','pickup_longitude']].values\n",
    "    df.drop(['rev'], axis=1)  \n",
    "    df = add_distances_features(df)\n",
    "    #since we designed more valuable feature we will not need original timestamp\n",
    "    df=df.drop(['pickup_datetime'],axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def clean_data(df, train):    \n",
    "    #remove data points outside appropriate ranges\n",
    "    criteria = (\n",
    "    \" 0 < fare_amount <= 250\"\n",
    "    \" and 0 < passenger_count <= 6 \"\n",
    "    \" and -76 <= pickup_longitude <= -72 \"\n",
    "    \" and -76 <= dropoff_longitude <= -72 \"\n",
    "    \" and 38 <= pickup_latitude <= 42 \"\n",
    "    \" and 38 <= dropoff_latitude <= 42 \"\n",
    "    )\n",
    "\n",
    "    if train == True:\n",
    "        df = (df\n",
    "              .dropna()\n",
    "              .query(criteria)\n",
    "             )\n",
    "    return df\n",
    "\n",
    "#execute functions of train dataset\n",
    "train = clean_data(train_raw, True)\n",
    "train = prepare_features(train)\n",
    "\n",
    "#split train data into input x and output y\n",
    "y_train=train['fare_amount'].values\n",
    "x_train= np.asarray(train.drop('fare_amount',axis=1).values).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>year</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>...</th>\n",
       "      <th>euclidean</th>\n",
       "      <th>manhattan</th>\n",
       "      <th>downtown_pickup_distance</th>\n",
       "      <th>downtown_dropoff_distance</th>\n",
       "      <th>jfk_pickup_distance</th>\n",
       "      <th>jfk_dropoff_distance</th>\n",
       "      <th>ewr_pickup_distance</th>\n",
       "      <th>ewr_dropoff_distance</th>\n",
       "      <th>lgr_pickup_distance</th>\n",
       "      <th>lgr_dropoff_distance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9031622</th>\n",
       "      <td>8.500000</td>\n",
       "      <td>-73.987869</td>\n",
       "      <td>40.765583</td>\n",
       "      <td>-73.974632</td>\n",
       "      <td>40.783310</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022124</td>\n",
       "      <td>0.030964</td>\n",
       "      <td>0.069931</td>\n",
       "      <td>0.100895</td>\n",
       "      <td>0.327068</td>\n",
       "      <td>0.331558</td>\n",
       "      <td>0.262718</td>\n",
       "      <td>0.293682</td>\n",
       "      <td>0.122284</td>\n",
       "      <td>0.117939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22554761</th>\n",
       "      <td>22.500000</td>\n",
       "      <td>-73.989304</td>\n",
       "      <td>40.726315</td>\n",
       "      <td>-73.921013</td>\n",
       "      <td>40.657829</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096715</td>\n",
       "      <td>0.136776</td>\n",
       "      <td>0.029228</td>\n",
       "      <td>0.141712</td>\n",
       "      <td>0.289234</td>\n",
       "      <td>0.152458</td>\n",
       "      <td>0.222015</td>\n",
       "      <td>0.286160</td>\n",
       "      <td>0.162987</td>\n",
       "      <td>0.163181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12970081</th>\n",
       "      <td>4.900000</td>\n",
       "      <td>-73.995384</td>\n",
       "      <td>40.733250</td>\n",
       "      <td>-73.990784</td>\n",
       "      <td>40.745449</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013038</td>\n",
       "      <td>0.016800</td>\n",
       "      <td>0.030083</td>\n",
       "      <td>0.046883</td>\n",
       "      <td>0.302250</td>\n",
       "      <td>0.309849</td>\n",
       "      <td>0.222870</td>\n",
       "      <td>0.239670</td>\n",
       "      <td>0.162132</td>\n",
       "      <td>0.145332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28899305</th>\n",
       "      <td>34.330002</td>\n",
       "      <td>-73.872513</td>\n",
       "      <td>40.774143</td>\n",
       "      <td>-73.978508</td>\n",
       "      <td>40.766727</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>303</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106254</td>\n",
       "      <td>0.113411</td>\n",
       "      <td>0.193848</td>\n",
       "      <td>0.080437</td>\n",
       "      <td>0.220272</td>\n",
       "      <td>0.318851</td>\n",
       "      <td>0.386635</td>\n",
       "      <td>0.273224</td>\n",
       "      <td>0.006653</td>\n",
       "      <td>0.111778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2065870</th>\n",
       "      <td>16.330000</td>\n",
       "      <td>-73.956367</td>\n",
       "      <td>40.747433</td>\n",
       "      <td>-73.977188</td>\n",
       "      <td>40.745403</td>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020919</td>\n",
       "      <td>0.022850</td>\n",
       "      <td>0.083282</td>\n",
       "      <td>0.060432</td>\n",
       "      <td>0.277416</td>\n",
       "      <td>0.296207</td>\n",
       "      <td>0.276070</td>\n",
       "      <td>0.253220</td>\n",
       "      <td>0.108932</td>\n",
       "      <td>0.131783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          fare_amount  pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
       "key                                                                           \n",
       "9031622      8.500000        -73.987869        40.765583         -73.974632   \n",
       "22554761    22.500000        -73.989304        40.726315         -73.921013   \n",
       "12970081     4.900000        -73.995384        40.733250         -73.990784   \n",
       "28899305    34.330002        -73.872513        40.774143         -73.978508   \n",
       "2065870     16.330000        -73.956367        40.747433         -73.977188   \n",
       "\n",
       "          dropoff_latitude  passenger_count  year  hour  day_of_week  \\\n",
       "key                                                                    \n",
       "9031622          40.783310                1  2015    18            5   \n",
       "22554761         40.657829                1  2012    17            5   \n",
       "12970081         40.745449                1  2011     7            1   \n",
       "28899305         40.766727                1  2013    20            2   \n",
       "2065870          40.745403                1  2014    14            5   \n",
       "\n",
       "          day_of_year  ...  euclidean  manhattan  downtown_pickup_distance  \\\n",
       "key                    ...                                                   \n",
       "9031622            17  ...   0.022124   0.030964                  0.069931   \n",
       "22554761          105  ...   0.096715   0.136776                  0.029228   \n",
       "12970081           60  ...   0.013038   0.016800                  0.030083   \n",
       "28899305          303  ...   0.106254   0.113411                  0.193848   \n",
       "2065870           102  ...   0.020919   0.022850                  0.083282   \n",
       "\n",
       "          downtown_dropoff_distance  jfk_pickup_distance  \\\n",
       "key                                                        \n",
       "9031622                    0.100895             0.327068   \n",
       "22554761                   0.141712             0.289234   \n",
       "12970081                   0.046883             0.302250   \n",
       "28899305                   0.080437             0.220272   \n",
       "2065870                    0.060432             0.277416   \n",
       "\n",
       "          jfk_dropoff_distance  ewr_pickup_distance  ewr_dropoff_distance  \\\n",
       "key                                                                         \n",
       "9031622               0.331558             0.262718              0.293682   \n",
       "22554761              0.152458             0.222015              0.286160   \n",
       "12970081              0.309849             0.222870              0.239670   \n",
       "28899305              0.318851             0.386635              0.273224   \n",
       "2065870               0.296207             0.276070              0.253220   \n",
       "\n",
       "          lgr_pickup_distance  lgr_dropoff_distance  \n",
       "key                                                  \n",
       "9031622              0.122284              0.117939  \n",
       "22554761             0.162987              0.163181  \n",
       "12970081             0.162132              0.145332  \n",
       "28899305             0.006653              0.111778  \n",
       "2065870              0.108932              0.131783  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "   1/2144 [..............................] - ETA: 43s - loss: 217.1311 - mse: 214.6925WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0135s vs `on_train_batch_end` time: 0.0211s). Check your callbacks.\n",
      "2144/2144 [==============================] - 73s 34ms/step - loss: 20.8542 - mse: 18.4178 - val_loss: 23.8494 - val_mse: 21.4131\n",
      "Epoch 2/20\n",
      "2144/2144 [==============================] - 72s 34ms/step - loss: 16.8361 - mse: 14.3998 - val_loss: 19.3311 - val_mse: 16.8949\n",
      "Epoch 3/20\n",
      "2144/2144 [==============================] - 73s 34ms/step - loss: 16.4095 - mse: 13.9731 - val_loss: 16.1548 - val_mse: 13.7186\n",
      "Epoch 4/20\n",
      "2144/2144 [==============================] - 73s 34ms/step - loss: 16.2064 - mse: 13.7700 - val_loss: 25.7684 - val_mse: 23.3321\n",
      "Epoch 5/20\n",
      "2144/2144 [==============================] - 73s 34ms/step - loss: 16.0219 - mse: 13.5855 - val_loss: 16.4433 - val_mse: 14.0070\n",
      "Epoch 6/20\n",
      "2144/2144 [==============================] - 73s 34ms/step - loss: 15.8759 - mse: 13.4394 - val_loss: 16.5665 - val_mse: 14.1303\n",
      "Epoch 7/20\n",
      "2144/2144 [==============================] - 73s 34ms/step - loss: 15.7460 - mse: 13.3096 - val_loss: 15.4416 - val_mse: 13.0053\n",
      "Epoch 8/20\n",
      "2144/2144 [==============================] - 73s 34ms/step - loss: 15.6673 - mse: 13.2309 - val_loss: 17.5451 - val_mse: 15.1089\n",
      "Epoch 9/20\n",
      "2144/2144 [==============================] - 73s 34ms/step - loss: 15.5828 - mse: 13.1464 - val_loss: 16.0797 - val_mse: 13.6434\n",
      "Epoch 10/20\n",
      "2144/2144 [==============================] - 74s 34ms/step - loss: 15.4485 - mse: 13.0121 - val_loss: 15.1233 - val_mse: 12.6871\n",
      "Epoch 11/20\n",
      "2144/2144 [==============================] - 73s 34ms/step - loss: 15.3176 - mse: 12.8812 - val_loss: 15.2886 - val_mse: 12.8524\n",
      "Epoch 12/20\n",
      "2144/2144 [==============================] - 73s 34ms/step - loss: 15.2345 - mse: 12.7981 - val_loss: 15.2832 - val_mse: 12.8470\n",
      "Epoch 13/20\n",
      "2144/2144 [==============================] - 73s 34ms/step - loss: 15.1825 - mse: 12.7462 - val_loss: 16.4229 - val_mse: 13.9866\n",
      "Epoch 14/20\n",
      "2144/2144 [==============================] - 73s 34ms/step - loss: 15.1348 - mse: 12.6984 - val_loss: 15.6063 - val_mse: 13.1701\n",
      "Epoch 15/20\n",
      "2144/2144 [==============================] - 73s 34ms/step - loss: 15.1205 - mse: 12.6841 - val_loss: 15.3219 - val_mse: 12.8857\n",
      "Epoch 16/20\n",
      "2144/2144 [==============================] - 73s 34ms/step - loss: 15.0713 - mse: 12.6349 - val_loss: 16.3397 - val_mse: 13.9035\n",
      "Epoch 17/20\n",
      "2144/2144 [==============================] - 73s 34ms/step - loss: 15.0184 - mse: 12.5820 - val_loss: 14.7995 - val_mse: 12.3633\n",
      "Epoch 18/20\n",
      "2144/2144 [==============================] - 73s 34ms/step - loss: 15.0018 - mse: 12.5654 - val_loss: 15.9445 - val_mse: 13.5083\n",
      "Epoch 19/20\n",
      "2144/2144 [==============================] - 73s 34ms/step - loss: 14.9791 - mse: 12.5427 - val_loss: 15.3206 - val_mse: 12.8844\n",
      "Epoch 20/20\n",
      "2144/2144 [==============================] - 73s 34ms/step - loss: 14.9389 - mse: 12.5025 - val_loss: 14.7819 - val_mse: 12.3456\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "#     tf.keras.layers.Dense(128, activation=tf.nn.leaky_relu),\n",
    "#     \n",
    "    tf.keras.layers.ActivityRegularization(l1=0.001),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(312, activation=tf.nn.leaky_relu),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(256, activation=tf.nn.leaky_relu),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.leaky_relu),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(256, activation=tf.nn.leaky_relu),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.leaky_relu),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(256, activation=tf.nn.leaky_relu),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.leaky_relu),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(256, activation=tf.nn.leaky_relu),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.leaky_relu),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(64, activation=tf.nn.leaky_relu),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(32, activation=tf.nn.leaky_relu),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(64, activation=tf.nn.leaky_relu),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(32, activation=tf.nn.leaky_relu),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(8, activation=tf.nn.leaky_relu),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "#and our optimizer\n",
    "opt = tf.keras.optimizers.Adam(lr=0.01)\n",
    "\n",
    "#define model loss and compile it\n",
    "model.compile(optimizer=opt,\n",
    "              loss='mse',\n",
    "              metrics=['mse'])\n",
    "\n",
    "#finally let's train our model\n",
    "\n",
    "\n",
    "metrics=model.fit(x_train, y_train,validation_split=0.1, epochs=20, batch_size=4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 14.6303 - mse: 12.1939 - val_loss: 15.1702 - val_mse: 12.7340\n",
      "Epoch 2/20\n",
      "2359/2359 [==============================] - 75s 32ms/step - loss: 14.5826 - mse: 12.1462 - val_loss: 15.3028 - val_mse: 12.8666\n",
      "Epoch 3/20\n",
      "2359/2359 [==============================] - 75s 32ms/step - loss: 14.5581 - mse: 12.1217 - val_loss: 14.9446 - val_mse: 12.5084\n",
      "Epoch 4/20\n",
      "2359/2359 [==============================] - 75s 32ms/step - loss: 14.5604 - mse: 12.1240 - val_loss: 15.2688 - val_mse: 12.8325\n",
      "Epoch 5/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 14.5239 - mse: 12.0875 - val_loss: 15.1171 - val_mse: 12.6809\n",
      "Epoch 6/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 14.5076 - mse: 12.0712 - val_loss: 15.4307 - val_mse: 12.9945\n",
      "Epoch 7/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 14.4841 - mse: 12.0477 - val_loss: 14.9680 - val_mse: 12.5317\n",
      "Epoch 8/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 14.4666 - mse: 12.0302 - val_loss: 15.1380 - val_mse: 12.7018\n",
      "Epoch 9/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 14.4302 - mse: 11.9939 - val_loss: 15.0929 - val_mse: 12.6566\n",
      "Epoch 10/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 14.4290 - mse: 11.9926 - val_loss: 14.9687 - val_mse: 12.5325\n",
      "Epoch 11/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 14.4050 - mse: 11.9686 - val_loss: 15.1312 - val_mse: 12.6950\n",
      "Epoch 12/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 14.3977 - mse: 11.9614 - val_loss: 15.1212 - val_mse: 12.6849\n",
      "Epoch 13/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 14.3715 - mse: 11.9351 - val_loss: 14.8908 - val_mse: 12.4546\n",
      "Epoch 14/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 14.3740 - mse: 11.9376 - val_loss: 15.0938 - val_mse: 12.6575\n",
      "Epoch 15/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 14.3582 - mse: 11.9218 - val_loss: 15.1808 - val_mse: 12.7445\n",
      "Epoch 16/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 14.3490 - mse: 11.9127 - val_loss: 15.6445 - val_mse: 13.2082\n",
      "Epoch 17/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 14.3366 - mse: 11.9002 - val_loss: 14.9785 - val_mse: 12.5423\n",
      "Epoch 18/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 14.3157 - mse: 11.8793 - val_loss: 15.8858 - val_mse: 13.4495\n",
      "Epoch 19/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 14.3227 - mse: 11.8863 - val_loss: 14.9063 - val_mse: 12.4700\n",
      "Epoch 20/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 14.3008 - mse: 11.8644 - val_loss: 15.0229 - val_mse: 12.5866\n"
     ]
    }
   ],
   "source": [
    "opt = tf.keras.optimizers.Adam(lr=0.004)\n",
    "\n",
    "#define model loss and compile it\n",
    "model.compile(optimizer=opt,\n",
    "              loss='mse',\n",
    "              metrics=['mse'])\n",
    "\n",
    "#finally let's train our model\n",
    "\n",
    "\n",
    "metrics=model.fit(x_train, y_train,validation_split=0.01, epochs=20, batch_size=4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 14.0930 - mse: 11.6567 - val_loss: 14.6419 - val_mse: 12.2056\n",
      "Epoch 2/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 14.0462 - mse: 11.6099 - val_loss: 14.6879 - val_mse: 12.2516\n",
      "Epoch 3/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 14.0439 - mse: 11.6075 - val_loss: 14.6585 - val_mse: 12.2223\n",
      "Epoch 4/20\n",
      "2359/2359 [==============================] - 75s 32ms/step - loss: 14.0313 - mse: 11.5950 - val_loss: 14.6318 - val_mse: 12.1956\n",
      "Epoch 5/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 14.0231 - mse: 11.5867 - val_loss: 14.6567 - val_mse: 12.2205\n",
      "Epoch 6/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 14.0126 - mse: 11.5761 - val_loss: 14.6719 - val_mse: 12.2357\n",
      "Epoch 7/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 14.0094 - mse: 11.5729 - val_loss: 14.6401 - val_mse: 12.2039\n",
      "Epoch 8/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 14.0002 - mse: 11.5638 - val_loss: 14.6681 - val_mse: 12.2318\n",
      "Epoch 9/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 13.9885 - mse: 11.5521 - val_loss: 14.6078 - val_mse: 12.1715\n",
      "Epoch 10/20\n",
      "2359/2359 [==============================] - 75s 32ms/step - loss: 13.9895 - mse: 11.5532 - val_loss: 14.5991 - val_mse: 12.1629\n",
      "Epoch 11/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 13.9872 - mse: 11.5508 - val_loss: 14.6442 - val_mse: 12.2079\n",
      "Epoch 12/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 13.9749 - mse: 11.5385 - val_loss: 14.6835 - val_mse: 12.2472\n",
      "Epoch 13/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 13.9648 - mse: 11.5284 - val_loss: 14.7042 - val_mse: 12.2679\n",
      "Epoch 14/20\n",
      "2359/2359 [==============================] - 75s 32ms/step - loss: 13.9606 - mse: 11.5242 - val_loss: 14.6535 - val_mse: 12.2173\n",
      "Epoch 15/20\n",
      "2359/2359 [==============================] - 75s 32ms/step - loss: 13.9497 - mse: 11.5133 - val_loss: 14.6251 - val_mse: 12.1889\n",
      "Epoch 16/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 13.9407 - mse: 11.5043 - val_loss: 14.7067 - val_mse: 12.2705\n",
      "Epoch 17/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 13.9415 - mse: 11.5051 - val_loss: 14.7976 - val_mse: 12.3614\n",
      "Epoch 18/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 13.9323 - mse: 11.4959 - val_loss: 14.5783 - val_mse: 12.1420\n",
      "Epoch 19/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 13.9397 - mse: 11.5033 - val_loss: 14.6966 - val_mse: 12.2604\n",
      "Epoch 20/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 13.9282 - mse: 11.4918 - val_loss: 14.6647 - val_mse: 12.2284\n"
     ]
    }
   ],
   "source": [
    "opt = tf.keras.optimizers.Adam(lr=0.0006)\n",
    "\n",
    "#define model loss and compile it\n",
    "model.compile(optimizer=opt,\n",
    "              loss='mse',\n",
    "              metrics=['mse'])\n",
    "\n",
    "#finally let's train our model\n",
    "\n",
    "\n",
    "metrics=model.fit(x_train, y_train,validation_split=0.01, epochs=20, batch_size=4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "   1/2359 [..............................] - ETA: 45s - loss: 11.1067 - mse: 8.6687WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0130s vs `on_train_batch_end` time: 0.0197s). Check your callbacks.\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 13.8748 - mse: 11.4385 - val_loss: 14.6400 - val_mse: 12.2038\n",
      "Epoch 2/20\n",
      "2359/2359 [==============================] - 75s 32ms/step - loss: 13.8712 - mse: 11.4348 - val_loss: 14.6286 - val_mse: 12.1923\n",
      "Epoch 3/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 13.8671 - mse: 11.4307 - val_loss: 14.6443 - val_mse: 12.2080\n",
      "Epoch 4/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 13.8660 - mse: 11.4296 - val_loss: 14.6274 - val_mse: 12.1912\n",
      "Epoch 5/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 13.8660 - mse: 11.4296 - val_loss: 14.6273 - val_mse: 12.1911\n",
      "Epoch 6/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 13.8610 - mse: 11.4247 - val_loss: 14.6290 - val_mse: 12.1927\n",
      "Epoch 7/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 13.8565 - mse: 11.4201 - val_loss: 14.6372 - val_mse: 12.2010\n",
      "Epoch 8/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 13.8566 - mse: 11.4202 - val_loss: 14.6332 - val_mse: 12.1970\n",
      "Epoch 9/20\n",
      "2359/2359 [==============================] - 75s 32ms/step - loss: 13.8622 - mse: 11.4259 - val_loss: 14.6420 - val_mse: 12.2058\n",
      "Epoch 10/20\n",
      "2359/2359 [==============================] - 75s 32ms/step - loss: 13.8515 - mse: 11.4151 - val_loss: 14.6320 - val_mse: 12.1958\n",
      "Epoch 11/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 13.8613 - mse: 11.4249 - val_loss: 14.6343 - val_mse: 12.1980\n",
      "Epoch 12/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 13.8585 - mse: 11.4221 - val_loss: 14.6385 - val_mse: 12.2022\n",
      "Epoch 13/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 13.8572 - mse: 11.4208 - val_loss: 14.6309 - val_mse: 12.1946\n",
      "Epoch 14/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 13.8559 - mse: 11.4195 - val_loss: 14.6321 - val_mse: 12.1959\n",
      "Epoch 15/20\n",
      "2359/2359 [==============================] - 75s 32ms/step - loss: 13.8572 - mse: 11.4208 - val_loss: 14.6485 - val_mse: 12.2123\n",
      "Epoch 16/20\n",
      "2359/2359 [==============================] - 75s 32ms/step - loss: 13.8534 - mse: 11.4170 - val_loss: 14.6469 - val_mse: 12.2106\n",
      "Epoch 17/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 13.8581 - mse: 11.4217 - val_loss: 14.6359 - val_mse: 12.1997\n",
      "Epoch 18/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 13.8604 - mse: 11.4240 - val_loss: 14.6334 - val_mse: 12.1972\n",
      "Epoch 19/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 13.8625 - mse: 11.4261 - val_loss: 14.6369 - val_mse: 12.2006\n",
      "Epoch 20/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 13.8649 - mse: 11.4285 - val_loss: 14.6340 - val_mse: 12.1977\n"
     ]
    }
   ],
   "source": [
    "opt = tf.keras.optimizers.Adam(lr=0.00001)\n",
    "\n",
    "#define model loss and compile it\n",
    "model.compile(optimizer=opt,\n",
    "              loss='mse',\n",
    "              metrics=['mse'])\n",
    "\n",
    "#finally let's train our model\n",
    "\n",
    "\n",
    "metrics=model.fit(x_train, y_train,validation_split=0.01, epochs=20, batch_size=4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(1,2,figsize = [15,5])\n",
    "ax[0].plot(metrics.history['loss'])\n",
    "ax[1].plot(metrics.history['mse'])\n",
    "ax[1].plot(metrics.history['val_mse'])\n",
    "\n",
    "ax[0].set_title('loss')\n",
    "ax[1].set_title('performance')\n",
    "ax[0].set_xlabel('epoch')\n",
    "ax[1].set_xlabel('epoch')\n",
    "ax[1].legend(['mse','val_mse'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv(\"test.csv\",index_col=0)\n",
    "x_test = np.asarray(prepare_features(test).values).astype('float32')\n",
    "\n",
    "y_test_predictions=model.predict(x_test)\n",
    "submission = pd.DataFrame(\n",
    "    {'key': test.index.values, 'fare_amount': y_test_predictions.squeeze()},\n",
    "    columns = ['key', 'fare_amount'])\n",
    "submission.to_csv('submission15.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system('cd ~/studia/kaggle/ && kaggle competitions submit -c gut-dla-2021-competition-1 -f submission15.csv -m \"16th try\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pg-ml)",
   "language": "python",
   "name": "pg-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
