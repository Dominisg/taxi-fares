{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import backend\n",
    "import numpy as np\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9031622</th>\n",
       "      <td>8.500000</td>\n",
       "      <td>2015-01-17 18:59:00</td>\n",
       "      <td>-73.987869</td>\n",
       "      <td>40.765583</td>\n",
       "      <td>-73.974632</td>\n",
       "      <td>40.783310</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22554761</th>\n",
       "      <td>22.500000</td>\n",
       "      <td>2012-04-14 17:31:00</td>\n",
       "      <td>-73.989304</td>\n",
       "      <td>40.726315</td>\n",
       "      <td>-73.921013</td>\n",
       "      <td>40.657829</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12970081</th>\n",
       "      <td>4.900000</td>\n",
       "      <td>2011-03-01 07:19:00</td>\n",
       "      <td>-73.995384</td>\n",
       "      <td>40.733250</td>\n",
       "      <td>-73.990784</td>\n",
       "      <td>40.745449</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28899305</th>\n",
       "      <td>34.330002</td>\n",
       "      <td>2013-10-30 20:05:00</td>\n",
       "      <td>-73.872513</td>\n",
       "      <td>40.774143</td>\n",
       "      <td>-73.978508</td>\n",
       "      <td>40.766727</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2065870</th>\n",
       "      <td>16.330000</td>\n",
       "      <td>2014-04-12 14:42:00</td>\n",
       "      <td>-73.956367</td>\n",
       "      <td>40.747433</td>\n",
       "      <td>-73.977188</td>\n",
       "      <td>40.745403</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42797114</th>\n",
       "      <td>11.300000</td>\n",
       "      <td>2009-08-07 08:48:00</td>\n",
       "      <td>-73.989250</td>\n",
       "      <td>40.740707</td>\n",
       "      <td>-73.959023</td>\n",
       "      <td>40.764175</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32346852</th>\n",
       "      <td>8.900000</td>\n",
       "      <td>2011-09-29 01:23:00</td>\n",
       "      <td>-73.979713</td>\n",
       "      <td>40.776134</td>\n",
       "      <td>-73.953529</td>\n",
       "      <td>40.768421</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43239639</th>\n",
       "      <td>11.500000</td>\n",
       "      <td>2012-11-15 15:11:00</td>\n",
       "      <td>-73.982742</td>\n",
       "      <td>40.762207</td>\n",
       "      <td>-73.978142</td>\n",
       "      <td>40.786243</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52252514</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>2015-05-08 19:56:00</td>\n",
       "      <td>-73.968582</td>\n",
       "      <td>40.754387</td>\n",
       "      <td>-74.003204</td>\n",
       "      <td>40.733601</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3708070</th>\n",
       "      <td>8.100000</td>\n",
       "      <td>2009-04-02 20:48:00</td>\n",
       "      <td>-73.946167</td>\n",
       "      <td>40.709930</td>\n",
       "      <td>-73.953033</td>\n",
       "      <td>40.708992</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          fare_amount     pickup_datetime  pickup_longitude  pickup_latitude  \\\n",
       "key                                                                            \n",
       "9031622      8.500000 2015-01-17 18:59:00        -73.987869        40.765583   \n",
       "22554761    22.500000 2012-04-14 17:31:00        -73.989304        40.726315   \n",
       "12970081     4.900000 2011-03-01 07:19:00        -73.995384        40.733250   \n",
       "28899305    34.330002 2013-10-30 20:05:00        -73.872513        40.774143   \n",
       "2065870     16.330000 2014-04-12 14:42:00        -73.956367        40.747433   \n",
       "42797114    11.300000 2009-08-07 08:48:00        -73.989250        40.740707   \n",
       "32346852     8.900000 2011-09-29 01:23:00        -73.979713        40.776134   \n",
       "43239639    11.500000 2012-11-15 15:11:00        -73.982742        40.762207   \n",
       "52252514    13.000000 2015-05-08 19:56:00        -73.968582        40.754387   \n",
       "3708070      8.100000 2009-04-02 20:48:00        -73.946167        40.709930   \n",
       "\n",
       "          dropoff_longitude  dropoff_latitude  passenger_count  \n",
       "key                                                             \n",
       "9031622          -73.974632         40.783310                1  \n",
       "22554761         -73.921013         40.657829                1  \n",
       "12970081         -73.990784         40.745449                1  \n",
       "28899305         -73.978508         40.766727                1  \n",
       "2065870          -73.977188         40.745403                1  \n",
       "42797114         -73.959023         40.764175                1  \n",
       "32346852         -73.953529         40.768421                2  \n",
       "43239639         -73.978142         40.786243                1  \n",
       "52252514         -74.003204         40.733601                2  \n",
       "3708070          -73.953033         40.708992                1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw=pd.read_pickle(\"train.pkl\")\n",
    "train_raw.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def manhattan(pickup_lat, pickup_long, dropoff_lat, dropoff_long):\n",
    "    return np.abs(dropoff_lat - pickup_lat) + np.abs(dropoff_long - pickup_long)\n",
    "\n",
    "def add_distances_features(df):\n",
    "    # Add distances from airpot and downtown\n",
    "    ny = (-74.0063889, 40.7141667)\n",
    "    jfk = (-73.7822222222, 40.6441666667)\n",
    "    ewr = (-74.175, 40.69)\n",
    "    lgr = (-73.87, 40.77)\n",
    "    \n",
    "    lat1 = df['pickup_latitude']\n",
    "    lat2 = df['dropoff_latitude']\n",
    "    lon1 = df['pickup_longitude']\n",
    "    lon2 = df['dropoff_longitude']\n",
    "    \n",
    "    df['euclidean'] = (df['diff_longitude'] ** 2 + df['diff_latitude'] ** 2) ** 0.5\n",
    "    df['manhattan'] = manhattan(lat1, lon1, lat2, lon2)\n",
    "    \n",
    "    df['downtown_pickup_distance'] = manhattan(ny[1], ny[0], lat1, lon1)\n",
    "    df['downtown_dropoff_distance'] = manhattan(ny[1], ny[0], lat2, lon2)\n",
    "    df['jfk_pickup_distance'] = manhattan(jfk[1], jfk[0], lat1, lon1)\n",
    "    df['jfk_dropoff_distance'] = manhattan(jfk[1], jfk[0], lat2, lon2)\n",
    "    df['ewr_pickup_distance'] = manhattan(ewr[1], ewr[0], lat1, lon1)\n",
    "    df['ewr_dropoff_distance'] = manhattan(ewr[1], ewr[0], lat2, lon2)\n",
    "    df['lgr_pickup_distance'] = manhattan(lgr[1], lgr[0], lat1, lon1)\n",
    "    df['lgr_dropoff_distance'] = manhattan(lgr[1], lgr[0], lat2, lon2)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def prepare_features(df):\n",
    "    dtcol=pd.DatetimeIndex(df['pickup_datetime'])    \n",
    "    df['year']=dtcol.year\n",
    "    df['hour']=dtcol.hour\n",
    "    df['day_of_week']=dtcol.dayofweek\n",
    "    df['day_of_year']=dtcol.dayofyear\n",
    "\n",
    "    df['diff_longitude'] = (df.dropoff_longitude -df.pickup_longitude).abs()\n",
    "    df['diff_latitude'] = (df.dropoff_latitude - df.pickup_latitude).abs()\n",
    "    \n",
    "    #reverse incorrectly assigned longitude/latitude values\n",
    "    df = df.assign(rev=df.dropoff_latitude<df.dropoff_longitude)\n",
    "    idx = (df['rev'] == 1)\n",
    "    df.loc[idx,['dropoff_longitude','dropoff_latitude']] = df.loc[idx,['dropoff_latitude','dropoff_longitude']].values\n",
    "    df.loc[idx,['pickup_longitude','pickup_latitude']] = df.loc[idx,['pickup_latitude','pickup_longitude']].values\n",
    "    df.drop(['rev'], axis=1)  \n",
    "    df = add_distances_features(df)\n",
    "    #since we designed more valuable feature we will not need original timestamp\n",
    "    df=df.drop(['pickup_datetime'],axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def clean_data(df, train):    \n",
    "    #remove data points outside appropriate ranges\n",
    "    criteria = (\n",
    "    \" 0 < fare_amount <= 250\"\n",
    "    \" and 0 < passenger_count <= 6 \"\n",
    "    \" and -76 <= pickup_longitude <= -72 \"\n",
    "    \" and -76 <= dropoff_longitude <= -72 \"\n",
    "    \" and 38 <= pickup_latitude <= 42 \"\n",
    "    \" and 38 <= dropoff_latitude <= 42 \"\n",
    "    )\n",
    "\n",
    "    if train == True:\n",
    "        df = (df\n",
    "              .dropna()\n",
    "              .query(criteria)\n",
    "             )\n",
    "    return df\n",
    "\n",
    "#execute functions of train dataset\n",
    "train = clean_data(train_raw, True)\n",
    "train = prepare_features(train)\n",
    "\n",
    "#split train data into input x and output y\n",
    "y_train=train['fare_amount'].values\n",
    "x_train= np.asarray(train.drop('fare_amount',axis=1).values).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>year</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>...</th>\n",
       "      <th>euclidean</th>\n",
       "      <th>manhattan</th>\n",
       "      <th>downtown_pickup_distance</th>\n",
       "      <th>downtown_dropoff_distance</th>\n",
       "      <th>jfk_pickup_distance</th>\n",
       "      <th>jfk_dropoff_distance</th>\n",
       "      <th>ewr_pickup_distance</th>\n",
       "      <th>ewr_dropoff_distance</th>\n",
       "      <th>lgr_pickup_distance</th>\n",
       "      <th>lgr_dropoff_distance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9031622</th>\n",
       "      <td>8.500000</td>\n",
       "      <td>-73.987869</td>\n",
       "      <td>40.765583</td>\n",
       "      <td>-73.974632</td>\n",
       "      <td>40.783310</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022124</td>\n",
       "      <td>0.030964</td>\n",
       "      <td>0.069931</td>\n",
       "      <td>0.100895</td>\n",
       "      <td>0.327068</td>\n",
       "      <td>0.331558</td>\n",
       "      <td>0.262718</td>\n",
       "      <td>0.293682</td>\n",
       "      <td>0.122284</td>\n",
       "      <td>0.117939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22554761</th>\n",
       "      <td>22.500000</td>\n",
       "      <td>-73.989304</td>\n",
       "      <td>40.726315</td>\n",
       "      <td>-73.921013</td>\n",
       "      <td>40.657829</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096715</td>\n",
       "      <td>0.136776</td>\n",
       "      <td>0.029228</td>\n",
       "      <td>0.141712</td>\n",
       "      <td>0.289234</td>\n",
       "      <td>0.152458</td>\n",
       "      <td>0.222015</td>\n",
       "      <td>0.286160</td>\n",
       "      <td>0.162987</td>\n",
       "      <td>0.163181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12970081</th>\n",
       "      <td>4.900000</td>\n",
       "      <td>-73.995384</td>\n",
       "      <td>40.733250</td>\n",
       "      <td>-73.990784</td>\n",
       "      <td>40.745449</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013038</td>\n",
       "      <td>0.016800</td>\n",
       "      <td>0.030083</td>\n",
       "      <td>0.046883</td>\n",
       "      <td>0.302250</td>\n",
       "      <td>0.309849</td>\n",
       "      <td>0.222870</td>\n",
       "      <td>0.239670</td>\n",
       "      <td>0.162132</td>\n",
       "      <td>0.145332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28899305</th>\n",
       "      <td>34.330002</td>\n",
       "      <td>-73.872513</td>\n",
       "      <td>40.774143</td>\n",
       "      <td>-73.978508</td>\n",
       "      <td>40.766727</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>303</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106254</td>\n",
       "      <td>0.113411</td>\n",
       "      <td>0.193848</td>\n",
       "      <td>0.080437</td>\n",
       "      <td>0.220272</td>\n",
       "      <td>0.318851</td>\n",
       "      <td>0.386635</td>\n",
       "      <td>0.273224</td>\n",
       "      <td>0.006653</td>\n",
       "      <td>0.111778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2065870</th>\n",
       "      <td>16.330000</td>\n",
       "      <td>-73.956367</td>\n",
       "      <td>40.747433</td>\n",
       "      <td>-73.977188</td>\n",
       "      <td>40.745403</td>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020919</td>\n",
       "      <td>0.022850</td>\n",
       "      <td>0.083282</td>\n",
       "      <td>0.060432</td>\n",
       "      <td>0.277416</td>\n",
       "      <td>0.296207</td>\n",
       "      <td>0.276070</td>\n",
       "      <td>0.253220</td>\n",
       "      <td>0.108932</td>\n",
       "      <td>0.131783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          fare_amount  pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
       "key                                                                           \n",
       "9031622      8.500000        -73.987869        40.765583         -73.974632   \n",
       "22554761    22.500000        -73.989304        40.726315         -73.921013   \n",
       "12970081     4.900000        -73.995384        40.733250         -73.990784   \n",
       "28899305    34.330002        -73.872513        40.774143         -73.978508   \n",
       "2065870     16.330000        -73.956367        40.747433         -73.977188   \n",
       "\n",
       "          dropoff_latitude  passenger_count  year  hour  day_of_week  \\\n",
       "key                                                                    \n",
       "9031622          40.783310                1  2015    18            5   \n",
       "22554761         40.657829                1  2012    17            5   \n",
       "12970081         40.745449                1  2011     7            1   \n",
       "28899305         40.766727                1  2013    20            2   \n",
       "2065870          40.745403                1  2014    14            5   \n",
       "\n",
       "          day_of_year  ...  euclidean  manhattan  downtown_pickup_distance  \\\n",
       "key                    ...                                                   \n",
       "9031622            17  ...   0.022124   0.030964                  0.069931   \n",
       "22554761          105  ...   0.096715   0.136776                  0.029228   \n",
       "12970081           60  ...   0.013038   0.016800                  0.030083   \n",
       "28899305          303  ...   0.106254   0.113411                  0.193848   \n",
       "2065870           102  ...   0.020919   0.022850                  0.083282   \n",
       "\n",
       "          downtown_dropoff_distance  jfk_pickup_distance  \\\n",
       "key                                                        \n",
       "9031622                    0.100895             0.327068   \n",
       "22554761                   0.141712             0.289234   \n",
       "12970081                   0.046883             0.302250   \n",
       "28899305                   0.080437             0.220272   \n",
       "2065870                    0.060432             0.277416   \n",
       "\n",
       "          jfk_dropoff_distance  ewr_pickup_distance  ewr_dropoff_distance  \\\n",
       "key                                                                         \n",
       "9031622               0.331558             0.262718              0.293682   \n",
       "22554761              0.152458             0.222015              0.286160   \n",
       "12970081              0.309849             0.222870              0.239670   \n",
       "28899305              0.318851             0.386635              0.273224   \n",
       "2065870               0.296207             0.276070              0.253220   \n",
       "\n",
       "          lgr_pickup_distance  lgr_dropoff_distance  \n",
       "key                                                  \n",
       "9031622              0.122284              0.117939  \n",
       "22554761             0.162987              0.163181  \n",
       "12970081             0.162132              0.145332  \n",
       "28899305             0.006653              0.111778  \n",
       "2065870              0.108932              0.131783  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "   1/2144 [..............................] - ETA: 43s - loss: 217.1311 - mse: 214.6925WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0135s vs `on_train_batch_end` time: 0.0211s). Check your callbacks.\n",
      "2144/2144 [==============================] - 73s 34ms/step - loss: 20.8542 - mse: 18.4178 - val_loss: 23.8494 - val_mse: 21.4131\n",
      "Epoch 2/20\n",
      "2144/2144 [==============================] - 72s 34ms/step - loss: 16.8361 - mse: 14.3998 - val_loss: 19.3311 - val_mse: 16.8949\n",
      "Epoch 3/20\n",
      "2144/2144 [==============================] - 73s 34ms/step - loss: 16.4095 - mse: 13.9731 - val_loss: 16.1548 - val_mse: 13.7186\n",
      "Epoch 4/20\n",
      "2144/2144 [==============================] - 73s 34ms/step - loss: 16.2064 - mse: 13.7700 - val_loss: 25.7684 - val_mse: 23.3321\n",
      "Epoch 5/20\n",
      "2144/2144 [==============================] - 73s 34ms/step - loss: 16.0219 - mse: 13.5855 - val_loss: 16.4433 - val_mse: 14.0070\n",
      "Epoch 6/20\n",
      "2144/2144 [==============================] - 73s 34ms/step - loss: 15.8759 - mse: 13.4394 - val_loss: 16.5665 - val_mse: 14.1303\n",
      "Epoch 7/20\n",
      "2144/2144 [==============================] - 73s 34ms/step - loss: 15.7460 - mse: 13.3096 - val_loss: 15.4416 - val_mse: 13.0053\n",
      "Epoch 8/20\n",
      "2144/2144 [==============================] - 73s 34ms/step - loss: 15.6673 - mse: 13.2309 - val_loss: 17.5451 - val_mse: 15.1089\n",
      "Epoch 9/20\n",
      "2144/2144 [==============================] - 73s 34ms/step - loss: 15.5828 - mse: 13.1464 - val_loss: 16.0797 - val_mse: 13.6434\n",
      "Epoch 10/20\n",
      "2144/2144 [==============================] - 74s 34ms/step - loss: 15.4485 - mse: 13.0121 - val_loss: 15.1233 - val_mse: 12.6871\n",
      "Epoch 11/20\n",
      "2144/2144 [==============================] - 73s 34ms/step - loss: 15.3176 - mse: 12.8812 - val_loss: 15.2886 - val_mse: 12.8524\n",
      "Epoch 12/20\n",
      "2144/2144 [==============================] - 73s 34ms/step - loss: 15.2345 - mse: 12.7981 - val_loss: 15.2832 - val_mse: 12.8470\n",
      "Epoch 13/20\n",
      "2144/2144 [==============================] - 73s 34ms/step - loss: 15.1825 - mse: 12.7462 - val_loss: 16.4229 - val_mse: 13.9866\n",
      "Epoch 14/20\n",
      "2144/2144 [==============================] - 73s 34ms/step - loss: 15.1348 - mse: 12.6984 - val_loss: 15.6063 - val_mse: 13.1701\n",
      "Epoch 15/20\n",
      "2144/2144 [==============================] - 73s 34ms/step - loss: 15.1205 - mse: 12.6841 - val_loss: 15.3219 - val_mse: 12.8857\n",
      "Epoch 16/20\n",
      "2144/2144 [==============================] - 73s 34ms/step - loss: 15.0713 - mse: 12.6349 - val_loss: 16.3397 - val_mse: 13.9035\n",
      "Epoch 17/20\n",
      "2144/2144 [==============================] - 73s 34ms/step - loss: 15.0184 - mse: 12.5820 - val_loss: 14.7995 - val_mse: 12.3633\n",
      "Epoch 18/20\n",
      "2144/2144 [==============================] - 73s 34ms/step - loss: 15.0018 - mse: 12.5654 - val_loss: 15.9445 - val_mse: 13.5083\n",
      "Epoch 19/20\n",
      "2144/2144 [==============================] - 73s 34ms/step - loss: 14.9791 - mse: 12.5427 - val_loss: 15.3206 - val_mse: 12.8844\n",
      "Epoch 20/20\n",
      "2144/2144 [==============================] - 73s 34ms/step - loss: 14.9389 - mse: 12.5025 - val_loss: 14.7819 - val_mse: 12.3456\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.ActivityRegularization(l1=0.001),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(312, activation=tf.nn.leaky_relu),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(256, activation=tf.nn.leaky_relu),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.leaky_relu),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(256, activation=tf.nn.leaky_relu),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.leaky_relu),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(256, activation=tf.nn.leaky_relu),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.leaky_relu),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(256, activation=tf.nn.leaky_relu),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.leaky_relu),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(64, activation=tf.nn.leaky_relu),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(32, activation=tf.nn.leaky_relu),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(64, activation=tf.nn.leaky_relu),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(32, activation=tf.nn.leaky_relu),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(8, activation=tf.nn.leaky_relu),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "#and our optimizer\n",
    "opt = tf.keras.optimizers.Adam(lr=0.01)\n",
    "\n",
    "#define model loss and compile it\n",
    "model.compile(optimizer=opt,\n",
    "              loss='mse',\n",
    "              metrics=['mse'])\n",
    "\n",
    "#finally let's train our model\n",
    "metrics=model.fit(x_train, y_train,validation_split=0.1, epochs=20, batch_size=4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 14.6303 - mse: 12.1939 - val_loss: 15.1702 - val_mse: 12.7340\n",
      "Epoch 2/20\n",
      "2359/2359 [==============================] - 75s 32ms/step - loss: 14.5826 - mse: 12.1462 - val_loss: 15.3028 - val_mse: 12.8666\n",
      "Epoch 3/20\n",
      "2359/2359 [==============================] - 75s 32ms/step - loss: 14.5581 - mse: 12.1217 - val_loss: 14.9446 - val_mse: 12.5084\n",
      "Epoch 4/20\n",
      "2359/2359 [==============================] - 75s 32ms/step - loss: 14.5604 - mse: 12.1240 - val_loss: 15.2688 - val_mse: 12.8325\n",
      "Epoch 5/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 14.5239 - mse: 12.0875 - val_loss: 15.1171 - val_mse: 12.6809\n",
      "Epoch 6/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 14.5076 - mse: 12.0712 - val_loss: 15.4307 - val_mse: 12.9945\n",
      "Epoch 7/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 14.4841 - mse: 12.0477 - val_loss: 14.9680 - val_mse: 12.5317\n",
      "Epoch 8/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 14.4666 - mse: 12.0302 - val_loss: 15.1380 - val_mse: 12.7018\n",
      "Epoch 9/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 14.4302 - mse: 11.9939 - val_loss: 15.0929 - val_mse: 12.6566\n",
      "Epoch 10/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 14.4290 - mse: 11.9926 - val_loss: 14.9687 - val_mse: 12.5325\n",
      "Epoch 11/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 14.4050 - mse: 11.9686 - val_loss: 15.1312 - val_mse: 12.6950\n",
      "Epoch 12/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 14.3977 - mse: 11.9614 - val_loss: 15.1212 - val_mse: 12.6849\n",
      "Epoch 13/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 14.3715 - mse: 11.9351 - val_loss: 14.8908 - val_mse: 12.4546\n",
      "Epoch 14/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 14.3740 - mse: 11.9376 - val_loss: 15.0938 - val_mse: 12.6575\n",
      "Epoch 15/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 14.3582 - mse: 11.9218 - val_loss: 15.1808 - val_mse: 12.7445\n",
      "Epoch 16/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 14.3490 - mse: 11.9127 - val_loss: 15.6445 - val_mse: 13.2082\n",
      "Epoch 17/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 14.3366 - mse: 11.9002 - val_loss: 14.9785 - val_mse: 12.5423\n",
      "Epoch 18/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 14.3157 - mse: 11.8793 - val_loss: 15.8858 - val_mse: 13.4495\n",
      "Epoch 19/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 14.3227 - mse: 11.8863 - val_loss: 14.9063 - val_mse: 12.4700\n",
      "Epoch 20/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 14.3008 - mse: 11.8644 - val_loss: 15.0229 - val_mse: 12.5866\n"
     ]
    }
   ],
   "source": [
    "opt = tf.keras.optimizers.Adam(lr=0.004)\n",
    "\n",
    "#define model loss and compile it\n",
    "model.compile(optimizer=opt,\n",
    "              loss='mse',\n",
    "              metrics=['mse'])\n",
    "\n",
    "#finally let's train our model\n",
    "metrics=model.fit(x_train, y_train,validation_split=0.01, epochs=20, batch_size=4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 14.0930 - mse: 11.6567 - val_loss: 14.6419 - val_mse: 12.2056\n",
      "Epoch 2/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 14.0462 - mse: 11.6099 - val_loss: 14.6879 - val_mse: 12.2516\n",
      "Epoch 3/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 14.0439 - mse: 11.6075 - val_loss: 14.6585 - val_mse: 12.2223\n",
      "Epoch 4/20\n",
      "2359/2359 [==============================] - 75s 32ms/step - loss: 14.0313 - mse: 11.5950 - val_loss: 14.6318 - val_mse: 12.1956\n",
      "Epoch 5/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 14.0231 - mse: 11.5867 - val_loss: 14.6567 - val_mse: 12.2205\n",
      "Epoch 6/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 14.0126 - mse: 11.5761 - val_loss: 14.6719 - val_mse: 12.2357\n",
      "Epoch 7/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 14.0094 - mse: 11.5729 - val_loss: 14.6401 - val_mse: 12.2039\n",
      "Epoch 8/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 14.0002 - mse: 11.5638 - val_loss: 14.6681 - val_mse: 12.2318\n",
      "Epoch 9/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 13.9885 - mse: 11.5521 - val_loss: 14.6078 - val_mse: 12.1715\n",
      "Epoch 10/20\n",
      "2359/2359 [==============================] - 75s 32ms/step - loss: 13.9895 - mse: 11.5532 - val_loss: 14.5991 - val_mse: 12.1629\n",
      "Epoch 11/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 13.9872 - mse: 11.5508 - val_loss: 14.6442 - val_mse: 12.2079\n",
      "Epoch 12/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 13.9749 - mse: 11.5385 - val_loss: 14.6835 - val_mse: 12.2472\n",
      "Epoch 13/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 13.9648 - mse: 11.5284 - val_loss: 14.7042 - val_mse: 12.2679\n",
      "Epoch 14/20\n",
      "2359/2359 [==============================] - 75s 32ms/step - loss: 13.9606 - mse: 11.5242 - val_loss: 14.6535 - val_mse: 12.2173\n",
      "Epoch 15/20\n",
      "2359/2359 [==============================] - 75s 32ms/step - loss: 13.9497 - mse: 11.5133 - val_loss: 14.6251 - val_mse: 12.1889\n",
      "Epoch 16/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 13.9407 - mse: 11.5043 - val_loss: 14.7067 - val_mse: 12.2705\n",
      "Epoch 17/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 13.9415 - mse: 11.5051 - val_loss: 14.7976 - val_mse: 12.3614\n",
      "Epoch 18/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 13.9323 - mse: 11.4959 - val_loss: 14.5783 - val_mse: 12.1420\n",
      "Epoch 19/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 13.9397 - mse: 11.5033 - val_loss: 14.6966 - val_mse: 12.2604\n",
      "Epoch 20/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 13.9282 - mse: 11.4918 - val_loss: 14.6647 - val_mse: 12.2284\n"
     ]
    }
   ],
   "source": [
    "opt = tf.keras.optimizers.Adam(lr=0.0006)\n",
    "\n",
    "#define model loss and compile it\n",
    "model.compile(optimizer=opt,\n",
    "              loss='mse',\n",
    "              metrics=['mse'])\n",
    "\n",
    "#finally let's train our model\n",
    "metrics=model.fit(x_train, y_train,validation_split=0.01, epochs=20, batch_size=4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "   1/2359 [..............................] - ETA: 45s - loss: 11.1067 - mse: 8.6687WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0130s vs `on_train_batch_end` time: 0.0197s). Check your callbacks.\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 13.8748 - mse: 11.4385 - val_loss: 14.6400 - val_mse: 12.2038\n",
      "Epoch 2/20\n",
      "2359/2359 [==============================] - 75s 32ms/step - loss: 13.8712 - mse: 11.4348 - val_loss: 14.6286 - val_mse: 12.1923\n",
      "Epoch 3/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 13.8671 - mse: 11.4307 - val_loss: 14.6443 - val_mse: 12.2080\n",
      "Epoch 4/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 13.8660 - mse: 11.4296 - val_loss: 14.6274 - val_mse: 12.1912\n",
      "Epoch 5/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 13.8660 - mse: 11.4296 - val_loss: 14.6273 - val_mse: 12.1911\n",
      "Epoch 6/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 13.8610 - mse: 11.4247 - val_loss: 14.6290 - val_mse: 12.1927\n",
      "Epoch 7/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 13.8565 - mse: 11.4201 - val_loss: 14.6372 - val_mse: 12.2010\n",
      "Epoch 8/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 13.8566 - mse: 11.4202 - val_loss: 14.6332 - val_mse: 12.1970\n",
      "Epoch 9/20\n",
      "2359/2359 [==============================] - 75s 32ms/step - loss: 13.8622 - mse: 11.4259 - val_loss: 14.6420 - val_mse: 12.2058\n",
      "Epoch 10/20\n",
      "2359/2359 [==============================] - 75s 32ms/step - loss: 13.8515 - mse: 11.4151 - val_loss: 14.6320 - val_mse: 12.1958\n",
      "Epoch 11/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 13.8613 - mse: 11.4249 - val_loss: 14.6343 - val_mse: 12.1980\n",
      "Epoch 12/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 13.8585 - mse: 11.4221 - val_loss: 14.6385 - val_mse: 12.2022\n",
      "Epoch 13/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 13.8572 - mse: 11.4208 - val_loss: 14.6309 - val_mse: 12.1946\n",
      "Epoch 14/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 13.8559 - mse: 11.4195 - val_loss: 14.6321 - val_mse: 12.1959\n",
      "Epoch 15/20\n",
      "2359/2359 [==============================] - 75s 32ms/step - loss: 13.8572 - mse: 11.4208 - val_loss: 14.6485 - val_mse: 12.2123\n",
      "Epoch 16/20\n",
      "2359/2359 [==============================] - 75s 32ms/step - loss: 13.8534 - mse: 11.4170 - val_loss: 14.6469 - val_mse: 12.2106\n",
      "Epoch 17/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 13.8581 - mse: 11.4217 - val_loss: 14.6359 - val_mse: 12.1997\n",
      "Epoch 18/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 13.8604 - mse: 11.4240 - val_loss: 14.6334 - val_mse: 12.1972\n",
      "Epoch 19/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 13.8625 - mse: 11.4261 - val_loss: 14.6369 - val_mse: 12.2006\n",
      "Epoch 20/20\n",
      "2359/2359 [==============================] - 76s 32ms/step - loss: 13.8649 - mse: 11.4285 - val_loss: 14.6340 - val_mse: 12.1977\n"
     ]
    }
   ],
   "source": [
    "opt = tf.keras.optimizers.Adam(lr=0.00001)\n",
    "\n",
    "#define model loss and compile it\n",
    "model.compile(optimizer=opt,\n",
    "              loss='mse',\n",
    "              metrics=['mse'])\n",
    "\n",
    "#finally let's train our model\n",
    "metrics=model.fit(x_train, y_train,validation_split=0.01, epochs=20, batch_size=4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test=pd.read_csv(\"test.csv\",index_col=0)\n",
    "x_test = np.asarray(prepare_features(test).values).astype('float32')\n",
    "\n",
    "y_test_predictions=model.predict(x_test)\n",
    "submission = pd.DataFrame(\n",
    "    {'key': test.index.values, 'fare_amount': y_test_predictions.squeeze()},\n",
    "    columns = ['key', 'fare_amount'])\n",
    "submission.to_csv('submission15.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system('cd ~/studia/kaggle/ && kaggle competitions submit -c gut-dla-2021-competition-1 -f submission15.csv -m \"16th try\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (RL)",
   "language": "python",
   "name": "rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
