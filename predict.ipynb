{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import backend\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# def init_session():\n",
    "#     tf_config = tf.ConfigProto()\n",
    "#     tf_config.allow_soft_placement = True\n",
    "#     tf_config.gpu_options.allow_growth = True\n",
    "#     tf_config.gpu_options.visible_device_list = str(0)\n",
    "#     sess=tf.Session(config=tf_config)\n",
    "\n",
    "#     keras.backend.set_session(sess)\n",
    "\n",
    "# init_session()\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9031622</th>\n",
       "      <td>8.500000</td>\n",
       "      <td>2015-01-17 18:59:00</td>\n",
       "      <td>-73.987869</td>\n",
       "      <td>40.765583</td>\n",
       "      <td>-73.974632</td>\n",
       "      <td>40.783310</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22554761</th>\n",
       "      <td>22.500000</td>\n",
       "      <td>2012-04-14 17:31:00</td>\n",
       "      <td>-73.989304</td>\n",
       "      <td>40.726315</td>\n",
       "      <td>-73.921013</td>\n",
       "      <td>40.657829</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12970081</th>\n",
       "      <td>4.900000</td>\n",
       "      <td>2011-03-01 07:19:00</td>\n",
       "      <td>-73.995384</td>\n",
       "      <td>40.733250</td>\n",
       "      <td>-73.990784</td>\n",
       "      <td>40.745449</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28899305</th>\n",
       "      <td>34.330002</td>\n",
       "      <td>2013-10-30 20:05:00</td>\n",
       "      <td>-73.872513</td>\n",
       "      <td>40.774143</td>\n",
       "      <td>-73.978508</td>\n",
       "      <td>40.766727</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2065870</th>\n",
       "      <td>16.330000</td>\n",
       "      <td>2014-04-12 14:42:00</td>\n",
       "      <td>-73.956367</td>\n",
       "      <td>40.747433</td>\n",
       "      <td>-73.977188</td>\n",
       "      <td>40.745403</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42797114</th>\n",
       "      <td>11.300000</td>\n",
       "      <td>2009-08-07 08:48:00</td>\n",
       "      <td>-73.989250</td>\n",
       "      <td>40.740707</td>\n",
       "      <td>-73.959023</td>\n",
       "      <td>40.764175</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32346852</th>\n",
       "      <td>8.900000</td>\n",
       "      <td>2011-09-29 01:23:00</td>\n",
       "      <td>-73.979713</td>\n",
       "      <td>40.776134</td>\n",
       "      <td>-73.953529</td>\n",
       "      <td>40.768421</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43239639</th>\n",
       "      <td>11.500000</td>\n",
       "      <td>2012-11-15 15:11:00</td>\n",
       "      <td>-73.982742</td>\n",
       "      <td>40.762207</td>\n",
       "      <td>-73.978142</td>\n",
       "      <td>40.786243</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52252514</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>2015-05-08 19:56:00</td>\n",
       "      <td>-73.968582</td>\n",
       "      <td>40.754387</td>\n",
       "      <td>-74.003204</td>\n",
       "      <td>40.733601</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3708070</th>\n",
       "      <td>8.100000</td>\n",
       "      <td>2009-04-02 20:48:00</td>\n",
       "      <td>-73.946167</td>\n",
       "      <td>40.709930</td>\n",
       "      <td>-73.953033</td>\n",
       "      <td>40.708992</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          fare_amount     pickup_datetime  pickup_longitude  pickup_latitude  \\\n",
       "key                                                                            \n",
       "9031622      8.500000 2015-01-17 18:59:00        -73.987869        40.765583   \n",
       "22554761    22.500000 2012-04-14 17:31:00        -73.989304        40.726315   \n",
       "12970081     4.900000 2011-03-01 07:19:00        -73.995384        40.733250   \n",
       "28899305    34.330002 2013-10-30 20:05:00        -73.872513        40.774143   \n",
       "2065870     16.330000 2014-04-12 14:42:00        -73.956367        40.747433   \n",
       "42797114    11.300000 2009-08-07 08:48:00        -73.989250        40.740707   \n",
       "32346852     8.900000 2011-09-29 01:23:00        -73.979713        40.776134   \n",
       "43239639    11.500000 2012-11-15 15:11:00        -73.982742        40.762207   \n",
       "52252514    13.000000 2015-05-08 19:56:00        -73.968582        40.754387   \n",
       "3708070      8.100000 2009-04-02 20:48:00        -73.946167        40.709930   \n",
       "\n",
       "          dropoff_longitude  dropoff_latitude  passenger_count  \n",
       "key                                                             \n",
       "9031622          -73.974632         40.783310                1  \n",
       "22554761         -73.921013         40.657829                1  \n",
       "12970081         -73.990784         40.745449                1  \n",
       "28899305         -73.978508         40.766727                1  \n",
       "2065870          -73.977188         40.745403                1  \n",
       "42797114         -73.959023         40.764175                1  \n",
       "32346852         -73.953529         40.768421                2  \n",
       "43239639         -73.978142         40.786243                1  \n",
       "52252514         -74.003204         40.733601                2  \n",
       "3708070          -73.953033         40.708992                1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw=pd.read_pickle(\"train.pkl\")\n",
    "train_raw.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manhattan(pickup_lat, pickup_long, dropoff_lat, dropoff_long):\n",
    "    return np.abs(dropoff_lat - pickup_lat) + np.abs(dropoff_long - pickup_long)\n",
    "\n",
    "def add_distances_features(df):\n",
    "    # Add distances from airpot and downtown\n",
    "    ny = (-74.0063889, 40.7141667)\n",
    "    jfk = (-73.7822222222, 40.6441666667)\n",
    "    ewr = (-74.175, 40.69)\n",
    "    lgr = (-73.87, 40.77)\n",
    "    \n",
    "    lat1 = df['pickup_latitude']\n",
    "    lat2 = df['dropoff_latitude']\n",
    "    lon1 = df['pickup_longitude']\n",
    "    lon2 = df['dropoff_longitude']\n",
    "    \n",
    "    df['euclidean'] = (df['latdiff'] ** 2 + df['londiff'] ** 2) ** 0.5\n",
    "    df['manhattan'] = manhattan(lat1, lon1, lat2, lon2)\n",
    "    \n",
    "    df['downtown_pickup_distance'] = manhattan(ny[1], ny[0], lat1, lon1)\n",
    "    df['downtown_dropoff_distance'] = manhattan(ny[1], ny[0], lat2, lon2)\n",
    "    df['jfk_pickup_distance'] = manhattan(jfk[1], jfk[0], lat1, lon1)\n",
    "    df['jfk_dropoff_distance'] = manhattan(jfk[1], jfk[0], lat2, lon2)\n",
    "    df['ewr_pickup_distance'] = manhattan(ewr[1], ewr[0], lat1, lon1)\n",
    "    df['ewr_dropoff_distance'] = manhattan(ewr[1], ewr[0], lat2, lon2)\n",
    "    df['lgr_pickup_distance'] = manhattan(lgr[1], lgr[0], lat1, lon1)\n",
    "    df['lgr_dropoff_distance'] = manhattan(lgr[1], lgr[0], lat2, lon2)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def prepare_features(df):\n",
    "    dtcol=pd.DatetimeIndex(df['pickup_datetime'])    \n",
    "    df['year']=dtcol.year\n",
    "    df['hour']=dtcol.hour\n",
    "    df['day_of_week']=dtcol.dayofweek\n",
    "    df['day_of_year']=dtcol.dayofyear\n",
    "\n",
    "    df['diff_longitude'] = (df.dropoff_longitude -df.pickup_longitude).abs()\n",
    "    df['diff_latitude'] = (df.dropoff_latitude - df.pickup_latitude).abs()\n",
    "    \n",
    "    #reverse incorrectly assigned longitude/latitude values\n",
    "    df = df.assign(rev=df.dropoff_latitude<df.dropoff_longitude)\n",
    "    idx = (df['rev'] == 1)\n",
    "    df.loc[idx,['dropoff_longitude','dropoff_latitude']] = df.loc[idx,['dropoff_latitude','dropoff_longitude']].values\n",
    "    df.loc[idx,['pickup_longitude','pickup_latitude']] = df.loc[idx,['pickup_latitude','pickup_longitude']].values\n",
    "    df.drop(['rev'], axis=1)  \n",
    "\n",
    "    #since we designed more valuable feature we will not need original timestamp\n",
    "    df=df.drop(['pickup_datetime'],axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def clean_data(df, train):    \n",
    "    #remove data points outside appropriate ranges\n",
    "    criteria = (\n",
    "    \" 0 < fare_amount <= 250\"\n",
    "    \" and 0 < passenger_count <= 6 \"\n",
    "    \" and -76 <= pickup_longitude <= -72 \"\n",
    "    \" and -76 <= dropoff_longitude <= -72 \"\n",
    "    \" and 38 <= pickup_latitude <= 42 \"\n",
    "    \" and 38 <= dropoff_latitude <= 42 \"\n",
    "    )\n",
    "\n",
    "    if train == True:\n",
    "        df = (df\n",
    "              .dropna()\n",
    "              .query(criteria)\n",
    "             )\n",
    "    return df\n",
    "\n",
    "#execute functions of train dataset\n",
    "train = clean_data(train_raw, True)\n",
    "train = prepare_features(train)\n",
    "\n",
    "#split train data into input x and output y\n",
    "y_train=train['fare_amount'].values\n",
    "x_train= np.asarray(train.drop('fare_amount',axis=1).values).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2144/2144 [==============================] - 48s 22ms/step - loss: 138.8616 - mse: 90.1662 - val_loss: 74.2249 - val_mse: 25.5324\n",
      "Epoch 2/20\n",
      "2144/2144 [==============================] - 48s 22ms/step - loss: 64.7253 - mse: 16.0297 - val_loss: 62.3381 - val_mse: 13.6457\n",
      "Epoch 3/20\n",
      "2144/2144 [==============================] - 48s 22ms/step - loss: 62.8431 - mse: 14.1476 - val_loss: 62.7173 - val_mse: 14.0249\n",
      "Epoch 4/20\n",
      "2144/2144 [==============================] - 48s 22ms/step - loss: 62.6203 - mse: 13.9247 - val_loss: 63.5706 - val_mse: 14.8782\n",
      "Epoch 5/20\n",
      "2144/2144 [==============================] - 48s 22ms/step - loss: 62.4314 - mse: 13.7359 - val_loss: 62.0671 - val_mse: 13.3747\n",
      "Epoch 6/20\n",
      "2144/2144 [==============================] - 47s 22ms/step - loss: 62.0555 - mse: 13.3600 - val_loss: 61.5398 - val_mse: 12.8474\n",
      "Epoch 9/20\n",
      "2144/2144 [==============================] - 47s 22ms/step - loss: 61.9745 - mse: 13.2790 - val_loss: 61.6669 - val_mse: 12.9744\n",
      "Epoch 10/20\n",
      "2144/2144 [==============================] - 47s 22ms/step - loss: 61.8596 - mse: 13.1642 - val_loss: 61.8506 - val_mse: 13.1582\n",
      "Epoch 11/20\n",
      "2144/2144 [==============================] - 47s 22ms/step - loss: 61.7737 - mse: 13.0783 - val_loss: 61.4818 - val_mse: 12.7893\n",
      "Epoch 12/20\n",
      "2080/2144 [============================>.] - ETA: 1s - loss: 61.6741 - mse: 12.9787"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "#     tf.keras.layers.Dense(128, activation=tf.nn.leaky_relu),\n",
    "#     \n",
    "    tf.keras.layers.ActivityRegularization(l1=0.02),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(312, activation=tf.nn.leaky_relu),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(256, activation=tf.nn.leaky_relu),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.leaky_relu),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(256, activation=tf.nn.leaky_relu),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.leaky_relu),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(64, activation=tf.nn.leaky_relu),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(32, activation=tf.nn.leaky_relu),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(8, activation=tf.nn.leaky_relu),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "#and our optimizer\n",
    "opt = tf.keras.optimizers.Adam(lr=0.0004)\n",
    "\n",
    "#define model loss and compile it\n",
    "model.compile(optimizer=opt,\n",
    "              loss='mse',\n",
    "              metrics=['mse'])\n",
    "\n",
    "#finally let's train our model\n",
    "\n",
    "\n",
    "metrics=model.fit(x_train, y_train,validation_split=0.1, epochs=20, batch_size=4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2359/2359 [==============================] - 51s 22ms/step - loss: 60.8130 - mse: 12.1178 - val_loss: 61.2219 - val_mse: 12.5296\n",
      "Epoch 2/20\n",
      "2359/2359 [==============================] - 51s 22ms/step - loss: 60.7518 - mse: 12.0566 - val_loss: 61.1761 - val_mse: 12.4838\n",
      "Epoch 3/20\n",
      "2359/2359 [==============================] - 51s 22ms/step - loss: 60.7235 - mse: 12.0283 - val_loss: 61.2115 - val_mse: 12.5192\n",
      "Epoch 4/20\n",
      "1903/2359 [=======================>......] - ETA: 9s - loss: 60.7039 - mse: 12.0089"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2359/2359 [==============================] - 51s 22ms/step - loss: 60.6800 - mse: 11.9849 - val_loss: 61.1276 - val_mse: 12.4353\n",
      "Epoch 6/20\n",
      "2359/2359 [==============================] - 51s 22ms/step - loss: 60.6760 - mse: 11.9807 - val_loss: 61.1709 - val_mse: 12.4786\n",
      "Epoch 7/20\n",
      "2359/2359 [==============================] - 51s 22ms/step - loss: 60.6518 - mse: 11.9566 - val_loss: 61.0535 - val_mse: 12.3612\n",
      "Epoch 8/20\n",
      "2359/2359 [==============================] - 51s 22ms/step - loss: 60.6410 - mse: 11.9459 - val_loss: 61.1217 - val_mse: 12.4294\n",
      "Epoch 9/20\n",
      "2359/2359 [==============================] - 51s 22ms/step - loss: 60.6282 - mse: 11.9330 - val_loss: 61.1588 - val_mse: 12.4665\n",
      "Epoch 10/20\n",
      "2359/2359 [==============================] - 51s 22ms/step - loss: 60.6281 - mse: 11.9328 - val_loss: 61.1493 - val_mse: 12.4570\n",
      "Epoch 11/20\n",
      "2359/2359 [==============================] - 51s 22ms/step - loss: 60.5998 - mse: 11.9046 - val_loss: 61.0195 - val_mse: 12.3272\n",
      "Epoch 12/20\n",
      "2359/2359 [==============================] - 51s 22ms/step - loss: 60.6007 - mse: 11.9055 - val_loss: 61.1375 - val_mse: 12.4452\n",
      "Epoch 13/20\n",
      "2359/2359 [==============================] - 51s 22ms/step - loss: 60.5848 - mse: 11.8895 - val_loss: 61.1157 - val_mse: 12.4234\n",
      "Epoch 14/20\n",
      "2359/2359 [==============================] - 51s 22ms/step - loss: 60.5694 - mse: 11.8741 - val_loss: 61.0293 - val_mse: 12.3370\n",
      "Epoch 15/20\n",
      "2359/2359 [==============================] - 51s 22ms/step - loss: 60.5514 - mse: 11.8562 - val_loss: 60.9724 - val_mse: 12.2801\n",
      "Epoch 16/20\n",
      "2359/2359 [==============================] - 51s 22ms/step - loss: 60.5563 - mse: 11.8611 - val_loss: 61.0744 - val_mse: 12.3821\n",
      "Epoch 17/20\n",
      "2359/2359 [==============================] - 51s 22ms/step - loss: 60.5433 - mse: 11.8480 - val_loss: 61.0075 - val_mse: 12.3152\n",
      "Epoch 18/20\n",
      " 358/2359 [===>..........................] - ETA: 43s - loss: 60.5824 - mse: 11.8869"
     ]
    }
   ],
   "source": [
    "opt = tf.keras.optimizers.Adam(lr=0.00006)\n",
    "\n",
    "#define model loss and compile it\n",
    "model.compile(optimizer=opt,\n",
    "              loss='mse',\n",
    "              metrics=['mse'])\n",
    "\n",
    "#finally let's train our model\n",
    "\n",
    "\n",
    "metrics=model.fit(x_train, y_train,validation_split=0.01, epochs=20, batch_size=4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2359/2359 [==============================] - 28s 12ms/step - loss: 61.3199 - mse: 12.6246 - val_loss: 61.7317 - val_mse: 13.0394\n",
      "Epoch 2/20\n",
      "2359/2359 [==============================] - 27s 12ms/step - loss: 61.2582 - mse: 12.5631 - val_loss: 61.7491 - val_mse: 13.0568\n",
      "Epoch 3/20\n",
      "2359/2359 [==============================] - 28s 12ms/step - loss: 61.2337 - mse: 12.5384 - val_loss: 61.7196 - val_mse: 13.0273\n",
      "Epoch 4/20\n",
      "2359/2359 [==============================] - 27s 12ms/step - loss: 61.2142 - mse: 12.5189 - val_loss: 61.6376 - val_mse: 12.9453\n",
      "Epoch 5/20\n",
      "2359/2359 [==============================] - 27s 12ms/step - loss: 61.1940 - mse: 12.4989 - val_loss: 61.6018 - val_mse: 12.9095\n",
      "Epoch 6/20\n",
      "2359/2359 [==============================] - 27s 12ms/step - loss: 61.1747 - mse: 12.4794 - val_loss: 61.6138 - val_mse: 12.9215\n",
      "Epoch 7/20\n",
      "2359/2359 [==============================] - 27s 12ms/step - loss: 61.1550 - mse: 12.4598 - val_loss: 61.5716 - val_mse: 12.8793\n",
      "Epoch 8/20\n",
      "2359/2359 [==============================] - 27s 12ms/step - loss: 61.1334 - mse: 12.4382 - val_loss: 61.5674 - val_mse: 12.8751\n",
      "Epoch 9/20\n",
      "2359/2359 [==============================] - 27s 12ms/step - loss: 61.1187 - mse: 12.4235 - val_loss: 61.5612 - val_mse: 12.8688\n",
      "Epoch 10/20\n",
      "2359/2359 [==============================] - 27s 12ms/step - loss: 61.1152 - mse: 12.4201 - val_loss: 61.5843 - val_mse: 12.8920\n",
      "Epoch 11/20\n",
      "2359/2359 [==============================] - 27s 11ms/step - loss: 61.0903 - mse: 12.3951 - val_loss: 61.5709 - val_mse: 12.8786\n",
      "Epoch 12/20\n",
      "2359/2359 [==============================] - 27s 11ms/step - loss: 61.0680 - mse: 12.3728 - val_loss: 61.5506 - val_mse: 12.8582\n",
      "Epoch 13/20\n",
      "2359/2359 [==============================] - 27s 12ms/step - loss: 61.0644 - mse: 12.3692 - val_loss: 61.5135 - val_mse: 12.8212\n",
      "Epoch 14/20\n",
      "2359/2359 [==============================] - 27s 12ms/step - loss: 61.0598 - mse: 12.3645 - val_loss: 61.5285 - val_mse: 12.8362\n",
      "Epoch 15/20\n",
      "2359/2359 [==============================] - 27s 12ms/step - loss: 61.0362 - mse: 12.3409 - val_loss: 61.5795 - val_mse: 12.8872\n",
      "Epoch 16/20\n",
      "2359/2359 [==============================] - 27s 12ms/step - loss: 61.0350 - mse: 12.3398 - val_loss: 61.5263 - val_mse: 12.8340\n",
      "Epoch 17/20\n",
      "2359/2359 [==============================] - 27s 12ms/step - loss: 61.0152 - mse: 12.3200 - val_loss: 61.4608 - val_mse: 12.7685\n",
      "Epoch 18/20\n",
      "2359/2359 [==============================] - 27s 12ms/step - loss: 61.0092 - mse: 12.3140 - val_loss: 61.3955 - val_mse: 12.7032\n",
      "Epoch 19/20\n",
      "2359/2359 [==============================] - 27s 12ms/step - loss: 60.9901 - mse: 12.2949 - val_loss: 61.5159 - val_mse: 12.8236\n",
      "Epoch 20/20\n",
      "2359/2359 [==============================] - 27s 12ms/step - loss: 60.9883 - mse: 12.2930 - val_loss: 61.5582 - val_mse: 12.8658\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1,2,figsize = [15,5])\n",
    "ax[0].plot(metrics.history['loss'])\n",
    "ax[1].plot(metrics.history['mse'])\n",
    "ax[1].plot(metrics.history['val_mse'])\n",
    "\n",
    "ax[0].set_title('loss')\n",
    "ax[1].set_title('performance')\n",
    "ax[0].set_xlabel('epoch')\n",
    "ax[1].set_xlabel('epoch')\n",
    "ax[1].legend(['mse','val_mse'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv(\"test.csv\",index_col=0)\n",
    "x_test = np.asarray(prepare_features(test).values).astype('float32')\n",
    "\n",
    "y_test_predictions=model.predict(x_test)\n",
    "submission = pd.DataFrame(\n",
    "    {'key': test.index.values, 'fare_amount': y_test_predictions.squeeze()},\n",
    "    columns = ['key', 'fare_amount'])\n",
    "submission.to_csv('submission9.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.system('cd ~/studia/kaggle/ && kaggle competitions submit -c gut-dla-2021-competition-1 -f submission9.csv -m \"9th try\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pg-ml)",
   "language": "python",
   "name": "pg-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
